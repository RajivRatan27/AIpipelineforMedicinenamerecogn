# -*- coding: utf-8 -*-
"""pipeline

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pHS1A5IHjxU8atmHsNRnC3ga9p0lzVis
"""



# ================================
# 1Ô∏è‚É£ Imports
# ================================
import cv2
import pytesseract
import easyocr
import numpy as np
import re
import spacy
from PIL import Image
from matplotlib import pyplot as plt
from pytesseract import Output
from transformers import pipeline

# ================================
# 2Ô∏è‚É£ OpenCV + OCR Preprocessing
# ================================
def preprocess_and_ocr(image_path):
    image = cv2.imread(image_path)
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # CLAHE + denoising + adaptive threshold
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    enhanced = clahe.apply(gray)
    blur = cv2.bilateralFilter(enhanced, 9, 75, 75)
    thresh = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                   cv2.THRESH_BINARY_INV, 31, 10)

    # Morphology
    kernel = np.ones((3, 3), np.uint8)
    morph = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=1)

    # OCR on whole image
    text_tesseract = pytesseract.image_to_string(morph)

    # EasyOCR
    reader = easyocr.Reader(['en'])
    text_easyocr = reader.readtext(image_path, detail=0)

    # Contour-based OCR
    contour_texts = []
    contours, _ = cv2.findContours(morph, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    for cnt in contours:
        x, y, w, h = cv2.boundingRect(cnt)
        if w * h > 500:
            roi = morph[y:y + h, x:x + w]
            text = pytesseract.image_to_string(roi, config='--psm 6')
            if text.strip():
                contour_texts.append(text.strip())
            cv2.rectangle(image, (x,y), (x+w, y+h), (0,255,0), 2)

    # Display
    plt.figure(figsize=(8,8))
    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    plt.title("Detected Regions with OCR")
    plt.axis('off')
    plt.show()

    return text_tesseract, text_easyocr, contour_texts

# ================================
# 3Ô∏è‚É£ Extract Large Text + Colored Boxes
# ================================
def extract_largest_text(image_path):
    img = Image.open(image_path)
    d = pytesseract.image_to_data(img, output_type=Output.DICT)
    n_boxes = len(d['level'])
    largest_text = ""
    largest_area = 0

    for i in range(n_boxes):
        text = d['text'][i]
        (x, y, w, h) = (d['left'][i], d['top'][i], d['width'][i], d['height'][i])
        area = w * h
        if area > largest_area and text.strip():
            largest_area = area
            largest_text = text.strip()
    return largest_text

def extract_colored_box_text(image_path):
    img = cv2.imread(image_path)
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)

    # Red range (example, can tune for your dataset)
    lower_red = np.array([0, 50, 50])
    upper_red = np.array([10, 255, 255])

    mask = cv2.inRange(hsv, lower_red, upper_red)
    kernel = np.ones((5, 5), np.uint8)
    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)

    result = cv2.bitwise_and(img, img, mask=mask)
    gray = cv2.cvtColor(result, cv2.COLOR_BGR2GRAY)
    _, binary = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY_INV)

    text = pytesseract.image_to_string(binary, config='--psm 6')
    return text.strip()

# ================================
# 4Ô∏è‚É£ NER + Custom Rules
# ================================
def clean_text(text):
    text = re.sub(r'\s+', ' ', text)
    text = re.sub(r'[^A-Za-z0-9\s.,-]', '', text)
    return text.strip()

def extract_product_name(text):
    pattern = r'\b[A-Za-z]+\s*\d+\b'
    return re.findall(pattern, text)

def ner_and_custom_rules(combined_text):
    nlp = spacy.load("en_core_web_sm")
    cleaned = clean_text(combined_text)
    doc = nlp(cleaned)

    entities = [(ent.text, ent.label_) for ent in doc.ents]
    product_names = extract_product_name(cleaned)

    print("\nüîπ Cleaned OCR Text:\n", cleaned)
    print("üîπ NER Entities:", entities)
    print("üîπ Product-like Names:", product_names)

    return cleaned

# ================================
# 5Ô∏è‚É£ DistilBERT Masked LM
# ================================
def masked_lm_prediction(cleaned_text, model_path):
    classifier = pipeline("fill-mask", model=model_path)

    text1 = f"{cleaned_text} [MASK]"
    preds1 = classifier(text1)

    text2 = f"[MASK] {cleaned_text}"
    preds2 = classifier(text2)

    print("\nüîπ DistilBERT Predictions (after text):")
    for p in preds1:
        print(f"{p['sequence']} (score: {p['score']:.4f})")

    print("\nüîπ DistilBERT Predictions (before text):")
    for p in preds2:
        print(f"{p['sequence']} (score: {p['score']:.4f})")

# ================================
# 6Ô∏è‚É£ Full Pipeline
# ================================
def full_pipeline(image_path, model_path):
    text_tess, text_easy, text_contour = preprocess_and_ocr(image_path)
    largest_text = extract_largest_text(image_path)
    colored_box_text = extract_colored_box_text(image_path)

    combined_text = ' '.join([text_tess] + text_easy + text_contour + [largest_text, colored_box_text])

    cleaned_text = ner_and_custom_rules(combined_text)

    masked_lm_prediction(cleaned_text, model_path)

# ================================
# üöÄ Run
# ================================
image_path_input = "/content/drive/My Drive/ciploxcut.jpg"
model_path_input = "/content/drive/MyDrive/distilbert_name_prediction"

full_pipeline(image_path_input, model_path_input)